{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(5000, 784)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "mnist_train_x = mnist.train.images\n",
    "mnist_train_y = mnist.train.labels\n",
    "mnist_train_y = np.argmax(mnist_train_y, axis=1)\n",
    "\n",
    "mnist_valid_x = mnist.validation.images\n",
    "mnist_valid_y = mnist.validation.labels\n",
    "mnist_valid_y = np.argmax(mnist_valid_y, axis=1)\n",
    "\n",
    "print mnist_train_x.shape\n",
    "print mnist_valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA0UlEQVR4nM3OvQ7BYBgF4IPqQgiS\nJiKxugEDNyARDAYRF+EezIYOOpTBz2CTEGNHJovFIgZrJxYD4ucwSFNp+63inb6cJ+d7X+An41dv\nWZEpXbImsKRKLtLeJmmkJguKbVIXLWw92QkKLHeg7hcVDc5TIoPJitBKnPgckb2kiunLkdmYwBEA\nkB8ZceevsRMLAELbKzl0NqUwADSWGRmIWpmF510GkXrv83ZdO+NqT5LkWnFh8f6hR9dtgEmSz3HZ\nTqRvHmz6vHjUAJjNgDf8z7wBKb5K7BwQoLgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "import PIL.Image\n",
    "from cStringIO import StringIO\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def display_digit(x):\n",
    "    x = np.reshape(x, [28, 28])\n",
    "    x = np.copy(x)\n",
    "    x *= 256\n",
    "    x = np.clip(x, 0., 255.)\n",
    "    x = x.astype(np.uint8)\n",
    "    \n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(x).save(f, 'png')\n",
    "    display(Image(data=f.getvalue()))\n",
    "\n",
    "i = 3\n",
    "display_digit(mnist_train_x[i])\n",
    "print mnist_train_y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "eps = 0.01\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "adv = tf.placeholder(tf.bool, [])\n",
    "\n",
    "with tf.variable_scope('adversary'):\n",
    "    yoh = tf.one_hot(y, 10)\n",
    "    xy = tf.concat([x, yoh], axis=1)\n",
    "    \n",
    "    with tf.variable_scope('h0'):\n",
    "        xadv = tf.layers.dense(xy, 392)\n",
    "    \n",
    "    with tf.variable_scope('output'):\n",
    "        xadv = tf.layers.dense(xadv, 784)\n",
    "    \n",
    "    xadv = eps * xadv\n",
    "\n",
    "with tf.variable_scope('classifier'):\n",
    "    xh = tf.cond(adv, lambda: x, lambda: x + xadv)\n",
    "    \n",
    "    with tf.variable_scope('h0'):\n",
    "        xh = tf.layers.dense(x, 392)\n",
    "        \n",
    "    with tf.variable_scope('softmax'):\n",
    "        xh = tf.layers.dense(xh, 10)\n",
    "\n",
    "nll = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=xh))\n",
    "\n",
    "preds = tf.argmax(xh, axis=1, output_type=tf.int32)\n",
    "correct = tf.equal(preds, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "cls_opt = tf.train.GradientDescentOptimizer(lr).minimize(nll, global_step=tf.train.get_or_create_global_step())\n",
    "adv_opt = tf.train.GradientDescentOptimizer(lr).minimize(-nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Validation accuracy: 0.097800001502\n",
      "Epoch 1\n",
      "Validation accuracy: 0.894400000572\n",
      "Epoch 2\n",
      "Validation accuracy: 0.907199978828\n",
      "Epoch 3\n",
      "Validation accuracy: 0.91219997406\n",
      "Epoch 4\n",
      "Validation accuracy: 0.916000008583\n",
      "Epoch 5\n",
      "Validation accuracy: 0.91939997673\n",
      "Epoch 6\n",
      "Validation accuracy: 0.920799970627\n",
      "Epoch 7\n",
      "Validation accuracy: 0.921599984169\n"
     ]
    }
   ],
   "source": [
    "nepochs = 8\n",
    "batch_size = 50\n",
    "_adv = False\n",
    "\n",
    "import random as random\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in xrange(nepochs):\n",
    "    print 'Epoch {}'.format(i)\n",
    "    \n",
    "    print 'Validation accuracy: {}'.format(sess.run(accuracy, {x: mnist_valid_x, y: mnist_valid_y, adv: False}))\n",
    "    \n",
    "    _is = set(range(mnist_train_x.shape[0]))\n",
    "    while len(_is) > batch_size:\n",
    "        _i = random.sample(_is, batch_size)\n",
    "        _is -= set(_i)\n",
    "        _x = np.take(mnist_train_x, _i, axis=0)\n",
    "        _y = np.take(mnist_train_y, _i, axis=0)\n",
    "        \n",
    "        if _adv:\n",
    "            _ = sess.run(adv_opt, {x: _x, y: _y, adv: _adv})\n",
    "        _ = sess.run(cls_opt, {x: _x, y: _y, adv: _adv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./reg-8'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './reg', global_step=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.25\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [784])\n",
    "y = tf.placeholder(tf.int32, [])\n",
    "yadv = tf.placeholder(tf.int32, [])\n",
    "\n",
    "xe = tf.expand_dims(x, axis=0)\n",
    "with tf.variable_scope('classifier'):\n",
    "    xh = xe\n",
    "    \n",
    "    with tf.variable_scope('h0'):\n",
    "        xh = tf.layers.dense(xh, 392)\n",
    "        \n",
    "    with tf.variable_scope('softmax'):\n",
    "        xh = tf.layers.dense(xh, 10)\n",
    "    \n",
    "    scores = xh[0]\n",
    "\n",
    "with tf.variable_scope('adv'):\n",
    "    xadv = tf.get_variable('adv', [784], tf.float32, initializer=tf.random_normal_initializer)\n",
    "xpert = xe + eps * tf.expand_dims(xadv, axis=0)\n",
    "    \n",
    "with tf.variable_scope('classifier', reuse=True):\n",
    "    xh = xpert\n",
    "    \n",
    "    with tf.variable_scope('h0'):\n",
    "        xh = tf.layers.dense(xh, 392)\n",
    "        \n",
    "    with tf.variable_scope('softmax'):\n",
    "        xh = tf.layers.dense(xh, 10)\n",
    "    \n",
    "    scores_adv = xh[0]\n",
    "cls_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='classifier')\n",
    "    \n",
    "nll_adv = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=yadv, logits=scores_adv))\n",
    "\n",
    "preds = tf.nn.softmax(scores)\n",
    "preds_adv = tf.nn.softmax(scores_adv)\n",
    "\n",
    "adv_opt = tf.train.GradientDescentOptimizer(lr).minimize(nll_adv, var_list=[xadv])\n",
    "\n",
    "saver = tf.train.Saver(cls_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from reg-8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA5klEQVR4nGNgoD9gRGJr+aSevsAw\n4Rc2demf/v379++fE1ZDhF78+/fv3793blhlM778e/Dv379e7A44/+/Sv3//lLBLhpz79+/fP00c\nbpe4+O/fv9VwLguyXLSeDgMDw1Fs2jSu/fr3D8VOJoSkpiLEmAKsNuZ9+/cPp52TbgswsEzmw+FY\nBgYGxoZ/t+VxSbL/+3dNBpdk179/JehiwhujGBgYGBgkP2AJviX/rturMBhHnvv3r5sDXdLy6L9/\n97Z8/Pfv71VuTLt6Mv/9+/fv3783yIIwf5aw8zAYRDJ8xB7TdAQABFdhZWAfWxoAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000806  0.0000909   0.00024036  0.99723971  0.00000011  0.00028115\n",
      "  0.00000012  0.00000687  0.0016862   0.00044652]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACZ0lEQVR4nC3QzWsbdADG8U/TJk2T\nviRrm77FLqxLXJqattloXePcbHWbmy1uTrHYonaOLp0deJiIKBVBRcdQhN4VLajXMVDw5MFVmAcH\nlU3Qw0DcdOzgQaQgPw/tH/B8n+/zGJbDvlc9FePE0d1QTce7+rKNSclH3dfvZIrqZDdLLeqN934i\nTgULozlZEK2NWTyvS6eDRU/EeD1GX8LOpUeIQg9woDWnRFIuLzmuXA2rpflxWbxCT1+d5d/udHw9\nffnx+sRagx/i5Qin6r9s2vH7FqDzJWUWhe9DWA1hFbL9e2ZOy9FIFvnXwn8b18PmuXzBcsmBSfLW\nZhszyktTZyph86tw4xoticQW03qWoxM6GtqkPwrv/hE+SLUeUie/B5xhCMxM/h3C7S9o3A4+Dcmo\nyQTPn9sM4V4CBgdTOvSKL0PmoHA1hLXPQ+EE9JIhpRCvccHpEG7evfPrh29EoHPHnLr+W45fUfgF\nf3b+tJH+9+fKsaa22+RTf8FF/bH5F4tStZyVEC5tCY2MxujJajetoQFp3Ss3Q+vsnPiMB1qdbePs\nXpK87cHd9SEE1La37DPPgAyXVBfvhm9K38EuK/SVx8pYH42acjX96a2N0Ur73MIkI1UeyuLHEIo4\ntn79/MsTDqE5s3XfcNO3CxfCP+Gz2r0QQjxCaruy+bEJ2D8UQrgRwjXJnZ55uL7vrXfQpi3WPtLd\npXZ4IYRw/GKRblreAzktntQ+UDkCUxHsx2jdLpx83yDDKGV7WqGaSdwPe8k1mX6zqCFiLDLU3CNd\n+NhhA7ItReUKyD8L0SOnniP+Qm5WQmHsf+qPpQlZov5fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000365  0.00002292  0.00030532  0.99676251  0.00000018  0.00031764\n",
      "  0.00000009  0.00000453  0.00238169  0.00020133]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nMWSvyvEYRzH368LdYoL\nwy1SinKK7gYLf4Iy2Wx2UqziDzCwSJmPwWo5pUwmg6S7QaIUC3XpCnV5m3zv8e05i8Fnep73u+f9\n49OD1X4yv3B/IDuCc/V4f6qola4W4mT2egA4bSEB+ZIHoK+SIIFn/2a3hqR6JSZrF5kAbmOy9lEJ\noBon/TQJzCfXsIrKV9eSZmKetUIn/PAM0tbumpKk7WjanSy09Vwerau59KroS9v+3GDkPl7FfofC\nQySQJGldWhxMyT7PlW3bj7nI+hYYO7vxxUEJ1t7S5Pk0DM/2Qma84TTp1V0AGAjTfffc+mjo8lC5\nkzAd//BvvwA4VTSKA9F6RQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.00648754,  0.        ,  0.20214675,  0.00001952,  0.00000001,\n",
      "        0.79105622,  0.00000244,  0.00000018,  0.0002873 ,  0.        ], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA5klEQVR4nGNgoD9gRGJr+aSevsAw\n4Rc2demf/v379++fE1ZDhF78+/fv3793blhlM778e/Dv379e7A44/+/Sv3//lLBLhpz79+/fP00c\nbpe4+O/fv9VwLguyXLSeDgMDw1Fs2jSu/fr3D8VOJoSkpiLEmAKsNuZ9+/cPp52TbgswsEzmw+FY\nBgYGxoZ/t+VxSbL/+3dNBpdk179/JehiwhujGBgYGBgkP2AJviX/rturMBhHnvv3r5sDXdLy6L9/\n97Z8/Pfv71VuTLt6Mv/9+/fv3783yIIwf5aw8zAYRDJ8xB7TdAQABFdhZWAfWxoAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000806  0.0000909   0.00024036  0.99723971  0.00000011  0.00028115\n",
      "  0.00000012  0.00000687  0.0016862   0.00044652]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACa0lEQVR4nDWRS0hUARiFP8eZ4Trj\njDNeZ67vca56fYyOjujkW2o0lbQyfOYrES3KIqIEMXKRaLRo04MKpVVrKchVLSRIqEgtcClFixYW\n0gMtCP4WY2d/Dt85h0oKsFJznX4ntLZnQBzlqj03TXO6cFWR4KUzCWqaNDjlwkHI/RATFAODIY1s\nANThEOPdFOChOsAxYMoOGRq+03VE5QNQOJiaST648ORCISllMps5UIALuAhqFkyeCB6igfKS5h8i\na5sCDHY57On7OZ4xcmAUWRG5LXILFHRD7xlDBwWcgH5Zfq+82tsdMzTmDlPUAIU87sRO/qWukXLZ\nuyMbzyHWkuiIhr7OhpZKfMklhO9J76rMuNx1aBgGAGcg4tBRPRORre/ybhHMUZ+pD+6T/tnRXebY\nNtdnOLGPQmxiU60HFd3MBMTZQyeRDZGFR6L1kg4GGGAnxzoNM3SKbH3Z/XRtKgEFdLWTGPcOR55R\n+sH8hx3XxzeeXy8jzc6fArrzK8BdsmL6BsqUlKsB05zIdJTmgD8OvBlAG940wEf2/HshXI85QnEK\n4+lwNgdqdZ7G9wQVkb9A+/6y1XSDh2yMZfX45DdZSF4CSGIekgMVGrAZTozrcr+NX1xf9YdsFT2t\nDvJroNwHvBAJAF3L6yODQUoBxZ8PQAlLg1fkrzw5vysiANr/M1sCAFWVIrItsobqZagR1/ws4MBi\nsSWYYSJyQUSGH9RBIfhvEMWy0wy2vDBAmw1oAQyTAQzNkwt5gOLEBBDyWfVoSfzQMRMGK1UWw2kj\nNfOm+ahbx6sUURUEIK0XwNLc0QvquWA/VoKN/wDE1adB8fgi/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0000673   0.00023437  0.00096288  0.09448223  0.00001231  0.00636823\n",
      "  0.00000707  0.00000759  0.89366025  0.00419784]\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "nadv = 1000\n",
    "\n",
    "#ckpt_fp = 'adv-135'\n",
    "ckpt_fp = 'reg-8'\n",
    "\n",
    "_x = mnist_valid_x[i]\n",
    "_y = mnist_valid_y[i]\n",
    "_yadv = 8\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, ckpt_fp)\n",
    "    \n",
    "    np.set_printoptions(suppress=True)\n",
    "    \n",
    "    _xpert, _preds, _preds_adv = sess.run([xpert, preds, preds_adv], {x: _x})\n",
    "    display_digit(_x)\n",
    "    print _preds\n",
    "    \n",
    "    display_digit(_xpert)\n",
    "    print _preds_adv\n",
    "    \n",
    "    _preds = sess.run([preds], {x: 1. - _x})\n",
    "    display_digit(1. - _x)\n",
    "    print _preds\n",
    "    \n",
    "    for i in xrange(nadv):\n",
    "        sess.run(adv_opt, {x: _x, yadv: _yadv})\n",
    "        \n",
    "    _xpert, _preds, _preds_adv = sess.run([xpert, preds, preds_adv], {x: _x})\n",
    "    display_digit(_x)\n",
    "    print _preds\n",
    "    \n",
    "    display_digit(_xpert)\n",
    "    print _preds_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Regular @ (eps=0.25, nadv=1000): [99.7%, 0.1%] -> [11.3%, 86.4%]\n",
    "* Adv @ (eps=0.25, nadv=1000): [90.4%, 0.2%] -> [64.3%, 15.1%]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
